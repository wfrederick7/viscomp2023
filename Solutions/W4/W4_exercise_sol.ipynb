{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Quickstart for Google Colab\n",
    "from pathlib import Path\n",
    "if Path.cwd().name != 'W4':\n",
    "  !git clone --quiet https://github.com/tavisualcomputing/viscomp2023/\n",
    "  %cd viscomp2023/Solutions/W4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Week 4: Fourier transform: filtering and sampling\n",
    "\n",
    "The exercise of this week is about Fourier Transform, image filtering and sampling. \n",
    "Run this notebook on Colab [following this link.](https://colab.research.google.com/github/tavisualcomputing/viscomp2023/blob/main/Solutions/W4/W4_exercise_sol.ipynb)\n",
    "\n",
    "First load the following libraries that will be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.fftpack import fft2, ifft2, fftshift\n",
    "from matplotlib.pyplot import imshow, show, figure\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the two images wall.jpg and sidewalk.jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall = imread('wall.jpg') / 255.\n",
    "wall_gray = rgb2gray(wall)\n",
    "imshow(wall)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = imread('sidewalk.jpg') / 255.\n",
    "side_gray = rgb2gray(side)\n",
    "imshow(side)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary question: which of the two images has the most low pass content? Which one has the most high pass content?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: the sidewalk presents a lot of uniform patches and few edges, so has more low pass content. On the contrary, the wall image has a lot of high frequency components due to the numerous edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will be useful in the course of this tutorial: `fft2`, `ifft2`, `convolve` from scipy and the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(shape, sigma):\n",
    "    \"\"\"\n",
    "    Returns a 2D gaussian filter specified by its shape and standard deviation.\n",
    "    \"\"\"\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m+1, -n:n+1]\n",
    "    h = np.exp(-(x * x + y * y) / (2. * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the magnitude of the Fourier coefficients for each of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FFT wall:')\n",
    "imshow(np.log(np.abs(fftshift(fft2(wall_gray)))), cmap='gray')\n",
    "show()\n",
    "\n",
    "print('FFT sidewalk:')\n",
    "imshow(np.log(np.abs(fftshift(fft2(side_gray)))), cmap='gray')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Filtering\n",
    "\n",
    "Create three Gaussian filters:\n",
    "- one 5x5 Gaussian low pass filter with standard deviation 1\n",
    "- one 15x15 Gaussian high pass filter with standard deviation $\\sigma=3.5$. Hint: the high pass content of an image can be extracted by subtracting the low pass filtered image from the original image. Hence, you can get a high pass filter kernel from a low pass one by subtracting the low pass filter kernel from a unit impulse filter. A unit impulse filter is a filter full of 0s with a single 1 in the middle, that once convolved with an image returns the same image.\n",
    "- one band pass filter. To do this, create first a 15x15 Gaussian filter with standard deviation 1 and then convolve this low pass filter with the previous high pass filter to create the band pass filter. Indeed, convolution is associative: \n",
    "$$\n",
    "I \\ast F_\\text{band-pass} = (I \\ast F_\\text{low-pass}) \\ast F_\\text{high-pass} = I \\ast (F_\\text{low-pass} \\ast F_\\text{high-pass})\n",
    "$$\n",
    "\n",
    "You can then visualize your filters in spatial and frequency domains (using `fft2` and `fftshift` from scipy for the latter). Since the filters are complex in the frequency domain, use `np.abs()` to display the magnitude of the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low pass filter\n",
    "print(\"Low pass filter:\")\n",
    "lpf = gaussian_filter((5, 5), 1)\n",
    "print(\"In spatial domain:\")\n",
    "imshow(lpf, cmap='gray')\n",
    "show()\n",
    "print(\"In frequency domain:\")\n",
    "imshow(np.abs(fftshift(fft2(lpf))), cmap='gray')\n",
    "show()\n",
    "\n",
    "# High pass filter\n",
    "print(\"High pass filter:\")\n",
    "hpf = gaussian_filter((15, 15), 3.5)\n",
    "hpf = -hpf\n",
    "hpf[7, 7] = hpf[7, 7] + 1.\n",
    "# Or use scipy.signal.unit_impulse((15, 15), idx='mid')\n",
    "print(\"In spatial domain:\")\n",
    "imshow(hpf, cmap='gray')\n",
    "show()\n",
    "print(\"In frequency domain:\")\n",
    "imshow(np.abs(fftshift(fft2(hpf))), cmap='gray')\n",
    "show()\n",
    "\n",
    "# # Band pass filter\n",
    "print(\"Band pass filter (frequency domain):\")\n",
    "bpf = convolve(gaussian_filter((15, 15), 1), hpf)\n",
    "imshow(np.abs(fftshift(fft2(bpf))), cmap='gray')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply these three filters to the two sample grayscale images in spatial domain first by convolving the image with the kernel, and in frequency domain secondly by taking the Fourier tranform of both the image and the filter kernel and multiplying them. Compare the runtimes of spatial and frequency domain filtering, using the `time` function of python. Compare the filtering results of two images by visualizing the filtered images in both spatial and frequency domains. Check that your initial guess about the low/high pass content of the images is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering in spatial domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image:\")\n",
    "imshow(wall_gray, cmap='gray')\n",
    "show()\n",
    "\n",
    "start = time()\n",
    "wall_lowp = convolve(wall_gray, lpf)\n",
    "end = time()\n",
    "print(\"Low pass filter:\")\n",
    "imshow(wall_lowp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "wall_highp = convolve(wall_gray, hpf)\n",
    "end = time()\n",
    "print(\"High pass filter:\")\n",
    "imshow(wall_highp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "wall_bandp = convolve(wall_gray, bpf)\n",
    "end = time()\n",
    "print(\"Band pass filter:\")\n",
    "imshow(wall_bandp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image:\")\n",
    "imshow(side_gray, cmap='gray')\n",
    "show()\n",
    "\n",
    "start = time()\n",
    "side_lowp = convolve(side_gray, lpf)\n",
    "end = time()\n",
    "print(\"Low pass filter:\")\n",
    "imshow(side_lowp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "side_highp = convolve(side_gray, hpf)\n",
    "end = time()\n",
    "print(\"High pass filter:\")\n",
    "imshow(side_highp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "side_bandp = convolve(side_gray, bpf)\n",
    "end = time()\n",
    "print(\"Band pass filter:\")\n",
    "imshow(side_bandp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering in frequency domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the output of `ifft2` is a numpy array with complex values with zero imaginary part (up to numerical precision). Extract the real component via the `.real` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image:\")\n",
    "imshow(wall_gray, cmap='gray')\n",
    "show()\n",
    "\n",
    "start = time()\n",
    "WALL = fft2(wall_gray)\n",
    "LPF = fft2(lpf, wall_gray.shape)\n",
    "WALL_LOWP = np.multiply(WALL, LPF)\n",
    "wall_lowp = ifft2(WALL_LOWP).real\n",
    "end = time()\n",
    "print(\"Low pass filter:\")\n",
    "imshow(wall_lowp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "WALL = fft2(wall_gray)\n",
    "HPF = fft2(hpf, wall_gray.shape)\n",
    "WALL_HIGHP = np.multiply(WALL, HPF)\n",
    "wall_highp = ifft2(WALL_HIGHP).real\n",
    "end = time()\n",
    "print(\"High pass filter:\")\n",
    "imshow(wall_highp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "WALL = fft2(wall_gray)\n",
    "BPF = fft2(bpf, wall_gray.shape)\n",
    "WALL_BANDP = np.multiply(WALL, BPF)\n",
    "wall_bandp = ifft2(WALL_BANDP).real\n",
    "end = time()\n",
    "print(\"Band pass filter:\")\n",
    "imshow(wall_bandp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image:\")\n",
    "imshow(side_gray, cmap='gray')\n",
    "show()\n",
    "\n",
    "start = time()\n",
    "SIDE = fft2(side_gray)\n",
    "LPF = fft2(lpf, side_gray.shape)\n",
    "SIDE_LOWP = np.multiply(SIDE, LPF)\n",
    "side_lowp = ifft2(SIDE_LOWP).real\n",
    "end = time()\n",
    "print(\"Low pass filter:\")\n",
    "imshow(side_lowp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "SIDE = fft2(side_gray)\n",
    "HPF = fft2(hpf, side_gray.shape)\n",
    "SIDE_HIGHP = np.multiply(SIDE, HPF)\n",
    "side_highp = ifft2(SIDE_HIGHP).real\n",
    "end = time()\n",
    "print(\"High pass filter:\")\n",
    "imshow(side_highp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()\n",
    "\n",
    "start = time()\n",
    "SIDE = fft2(side_gray)\n",
    "BPF = fft2(bpf, side_gray.shape)\n",
    "SIDE_BANDP = np.multiply(SIDE, BPF)\n",
    "side_bandp = ifft2(SIDE_BANDP).real\n",
    "end = time()\n",
    "print(\"Band pass filter:\")\n",
    "imshow(side_bandp, cmap='gray')\n",
    "show()\n",
    "print(\"Timing:\", end - start)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Sampling\n",
    "\n",
    "Downsample both images to one fourth of the resolution by taking every second row and column. You can use numpy array slicing for this: `my_array[start:end:step]`. Compare the results in terms of distortions and unexpected effects. Explain why the quality of the two downsampled images differ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_wall = wall[::2, ::2, :]\n",
    "print(\"Downsampled wall image:\")\n",
    "figure(dpi=200)\n",
    "imshow(wall)\n",
    "\n",
    "figure(dpi=200)\n",
    "imshow(downsampled_wall)\n",
    "show()\n",
    "\n",
    "downsampled_side = side[::2, ::2, :]\n",
    "print(\"Downsampled sidewalk image:\")\n",
    "figure(dpi=200)\n",
    "imshow(side)\n",
    "\n",
    "figure(dpi=200)\n",
    "imshow(downsampled_side)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downsampled wall image suffers from undesired artifacts due to the great number of high frequency components. This phenomenon is called aliasing. The low frequency sidewalk image does not have those artifacts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three 15x15 Gaussian low pass filters with standard deviations 0.5, 1 and 1.5 and apply them to the color image wall.jpg. You can filter the three channels separately and gather them in an RGB image with the numpy function `np.stack([r_img, g_img, b_img], axis=-1)`. Downsample the three filtered images to one fourth resolution. Compare the resulting downsampled images in terms of quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the filters\n",
    "lpf0 = gaussian_filter((15, 15), 0.5)\n",
    "lpf1 = gaussian_filter((15, 15), 1)\n",
    "lpf2 = gaussian_filter((15, 15), 1.5)\n",
    "\n",
    "# Convolve them with the RGB image\n",
    "wall_lowp0 = np.stack([convolve(wall[:, :, 0], lpf0), convolve(wall[:, :, 1], lpf0), convolve(wall[:, :, 2], lpf0)], axis=-1)\n",
    "\n",
    "wall_lowp1 = np.stack([convolve(wall[:, :, 0], lpf1), convolve(wall[:, :, 1], lpf1), convolve(wall[:, :, 2], lpf1)], axis=-1)\n",
    "wall_lowp2 = np.stack([convolve(wall[:, :, 0], lpf2), convolve(wall[:, :, 1], lpf2), convolve(wall[:, :, 2], lpf2)], axis=-1)\n",
    "\n",
    "print(\"Downsampled image without filtering:\")\n",
    "figure(dpi=200)\n",
    "imshow(downsampled_wall)\n",
    "\n",
    "# Downsample the resulting images\n",
    "wall_lowp0 = wall_lowp0[::2, ::2, :]\n",
    "print(\"Downsampled image after filter 0:\")\n",
    "figure(dpi=200)\n",
    "imshow(wall_lowp0)\n",
    "show()\n",
    "\n",
    "wall_lowp1 = wall_lowp1[::2, ::2, :]\n",
    "print(\"Downsampled image after filter 1:\")\n",
    "figure(dpi=200)\n",
    "imshow(wall_lowp1)\n",
    "show()\n",
    "\n",
    "wall_lowp2 = wall_lowp2[::2, ::2, :]\n",
    "print(\"Downsampled image after filter 2:\")\n",
    "figure(dpi=200)\n",
    "imshow(wall_lowp2)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the high pass content of the image more and more results in decreasing aliasing artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: for those that finished earlier\n",
    "\n",
    "Load the blurred road signs image and using your fresh knowledge about filters, design the perfect filter to make the text readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_road_signs = imread('blurred_road_signs.jpg', as_gray=True) / 255.\n",
    "\n",
    "figure(figsize=(10, 10))\n",
    "imshow(blurred_road_signs, cmap='gray')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a high pass filter to sharpen the text\n",
    "hpf = gaussian_filter((5, 5), 1.5)\n",
    "hpf = -hpf\n",
    "hpf[2, 2] = hpf[2, 2] + 1\n",
    "\n",
    "sharpened_road_signs = convolve(blurred_road_signs, hpf)\n",
    "figure(figsize=(10, 10))\n",
    "imshow(sharpened_road_signs, cmap='gray')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt](exam_questions/Q_B1.png)\n",
    "_Answer:_\n",
    "![alt](exam_questions/A_B1.png)\n",
    "![alt](exam_questions/Q_B2_1.png)\n",
    "![alt](exam_questions/Q_B2_2.png)\n",
    "_Answer:_\n",
    "![alt](exam_questions/A_B2.png)\n",
    "![alt](exam_questions/Q_C1.png)\n",
    "_Answer:_\n",
    "![alt](exam_questions/A_C1.png)\n",
    "![alt](exam_questions/Q_C2.png)\n",
    "_Answer:_\n",
    "![alt](exam_questions/A_C2.png)\n",
    "![alt](exam_questions/Q_C3.png)\n",
    "_Answer:_\n",
    "![alt](exam_questions/A_C3.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
